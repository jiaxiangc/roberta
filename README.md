# NLP Course Final Project: RoBERTa Model Training on RACE Dataset

This repository contains the code and resources for my NLP course final project at Beijing University of Aeronautics and Astronautics (BUAA). The objective of this project is to train a RoBERTa model on the RACE dataset and provide evaluation metrics for the model's performance.

## About the RACE Dataset

The RACE (Reading Comprehension from Examinations) dataset is a large-scale dataset designed for text comprehension tasks. It consists of various reading passages and associated questions, covering a wide range of topics. The dataset is widely used for evaluating machine reading comprehension models.


## Project Goals

The main goals of this project are as follows:

- Train a RoBERTa model on the RACE dataset using state-of-the-art NLP techniques.
- Evaluate the performance of the trained model using various metrics, such as accuracy, precision, recall, and F1 score.
- Explore different pre-processing techniques, model architectures, and hyperparameter tuning strategies to enhance the model's performance.


## Contact Information
If you have any questions or suggestions regarding this project, please feel free to reach out to me.

Name: Jiaxiang Cheng
Email: jiaxiangcc@gmail.com


## Acknowledgments
I would like to express my gratitude to my instructor, Professor Lei Sha, for providing guidance and support throughout this NLP course and project.
